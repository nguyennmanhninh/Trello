# ğŸ¤– RAG SYSTEM SETUP GUIDE

## âœ… HOÃ€N THÃ€NH! RAG System Infrastructure Ready

### Nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘Æ°á»£c táº¡o:

1. âœ… **RagService.cs** - Backend RAG service vá»›i OpenAI integration
2. âœ… **ChatController.cs** - API endpoint `/api/chat/ask`
3. âœ… **AiChatService.ts** - Angular service for calling RAG API
4. âœ… **AiChatComponent** - Beautiful chat UI vá»›i code sources display
5. âœ… **Configuration** - appsettings.json vá»›i OpenAI + Pinecone placeholders

---

## ğŸš€ QUICK START (30 PHÃšT)

### BÆ¯á»šC 1: Láº¥y OpenAI API Key (5 phÃºt)

1. **Truy cáº­p**: https://platform.openai.com/
2. **Sign Up** (free $5 credit cho new users)
3. **API Keys** â†’ Create new secret key
4. **Copy** key (chá»‰ hiá»‡n 1 láº§n!)

**Pricing:**
- gpt-3.5-turbo: ~$0.002 / 1K tokens (ráº», nhanh)
- gpt-4-turbo-preview: ~$0.01 / 1K tokens (thÃ´ng minh hÆ¡n)
- text-embedding-ada-002: ~$0.0001 / 1K tokens (embedding)

**Cost estimate:** ~$0.50 / 100 cÃ¢u há»i vá»›i GPT-4

### BÆ¯á»šC 2: Cáº­p nháº­t API Key

Má»Ÿ: `appsettings.Development.json`

```json
{
  "OpenAI": {
    "ApiKey": "sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxx", // â† Paste key here
    "Model": "gpt-4-turbo-preview" // hoáº·c "gpt-3.5-turbo" cho ráº» hÆ¡n
  }
}
```

### BÆ¯á»šC 3: Build Backend

```powershell
cd c:\Users\TDG\source\repos\StudentManagementSystem\StudentManagementSystem
dotnet build
dotnet run
```

### BÆ¯á»šC 4: Test RAG API

```powershell
# Test health endpoint
curl http://localhost:5298/api/chat/health

# Test ask endpoint (without vector DB - sáº½ dÃ¹ng sample docs)
curl -X POST http://localhost:5298/api/chat/ask `
  -H "Content-Type: application/json" `
  -d '{"question": "LÃ m sao StudentController validate Ä‘iá»ƒm?"}'
```

### BÆ¯á»šC 5: Run Angular

```powershell
cd ClientApp
npm start
```

### BÆ¯á»šC 6: Test UI!

1. Má»Ÿ: http://localhost:4200
2. Click nÃºt **"ğŸ¤– AI Assistant"** gÃ³c pháº£i dÆ°á»›i
3. Há»i: **"LÃ m sao StudentController validate Ä‘iá»ƒm sá»‘?"**
4. AI sáº½ tráº£ lá»i vá»›i code snippets! ğŸ‰

---

## ğŸ”¥ NÃ‚NG CAO: Setup Vector Database (Optional - 1-2 giá»)

### Option A: Pinecone (RECOMMENDED - Free tier)

**Táº¡i sao cáº§n Vector DB?**
- Current: RAG dÃ¹ng **sample docs** hardcoded trong code
- With Vector DB: Bot sáº½ **search toÃ n bá»™ codebase** thá»±c sá»±

**Setup:**

1. **ÄÄƒng kÃ½ Pinecone**:
   - https://www.pinecone.io/
   - Free tier: 1 index, 100K vectors
   
2. **Create Index**:
   - Name: `sms-codebase`
   - Dimensions: `1536` (OpenAI ada-002 embedding size)
   - Metric: `cosine`

3. **Get API Key**:
   - Settings â†’ API Keys â†’ Copy

4. **Update Config**:
   ```json
   {
     "Pinecone": {
       "ApiKey": "your-pinecone-api-key",
       "Environment": "us-east-1-aws", // tá»« dashboard
       "IndexName": "sms-codebase"
     }
   }
   ```

### Option B: ChromaDB (Local - Free)

**Install:**
```powershell
pip install chromadb
```

**Run Server:**
```powershell
chroma run --host localhost --port 8000
```

**Update RagService.cs** Ä‘á»ƒ call ChromaDB thay vÃ¬ Pinecone (cáº§n sá»­a code)

---

## ğŸ“š INDEX CODEBASE VÃ€O VECTOR DB

### Script Python Ä‘á»ƒ index files:

```python
# index_codebase.py
import os
import openai
from pinecone import Pinecone

# Config
openai.api_key = "YOUR_OPENAI_KEY"
pc = Pinecone(api_key="YOUR_PINECONE_KEY")
index = pc.Index("sms-codebase")

# Files to index
file_extensions = ['.cs', '.ts', '.html', '.scss']
root_dir = "c:/Users/TDG/source/repos/StudentManagementSystem/StudentManagementSystem"

def chunk_code(content, chunk_size=1000):
    """Split code into chunks"""
    lines = content.split('\n')
    chunks = []
    current_chunk = []
    current_size = 0
    
    for line in lines:
        current_chunk.append(line)
        current_size += len(line)
        
        if current_size >= chunk_size:
            chunks.append('\n'.join(current_chunk))
            current_chunk = []
            current_size = 0
    
    if current_chunk:
        chunks.append('\n'.join(current_chunk))
    
    return chunks

def get_embedding(text):
    """Generate embedding using OpenAI"""
    response = openai.Embedding.create(
        model="text-embedding-ada-002",
        input=text
    )
    return response['data'][0]['embedding']

def index_file(file_path, relative_path):
    """Index a single file"""
    print(f"Indexing: {relative_path}")
    
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
        content = f.read()
    
    # Skip empty files
    if not content.strip():
        return
    
    # Split into chunks
    chunks = chunk_code(content)
    
    # Index each chunk
    for i, chunk in enumerate(chunks):
        chunk_id = f"{relative_path}_chunk_{i}"
        
        # Generate embedding
        embedding = get_embedding(chunk)
        
        # Upsert to Pinecone
        index.upsert(vectors=[{
            "id": chunk_id,
            "values": embedding,
            "metadata": {
                "fileName": os.path.basename(file_path),
                "filePath": relative_path,
                "fileType": os.path.splitext(file_path)[1][1:],
                "content": chunk,
                "chunkIndex": i
            }
        }])
        
        print(f"  âœ“ Chunk {i+1}/{len(chunks)}")

def index_all_files():
    """Index all files in the project"""
    print("ğŸš€ Starting indexing...")
    
    file_count = 0
    for root, dirs, files in os.walk(root_dir):
        # Skip node_modules, bin, obj
        dirs[:] = [d for d in dirs if d not in ['node_modules', 'bin', 'obj', '.git']]
        
        for file in files:
            if any(file.endswith(ext) for ext in file_extensions):
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, root_dir)
                
                try:
                    index_file(file_path, relative_path)
                    file_count += 1
                except Exception as e:
                    print(f"  âœ— Error: {e}")
    
    print(f"\nâœ… Indexed {file_count} files!")

if __name__ == "__main__":
    index_all_files()
```

**Run script:**
```powershell
python index_codebase.py
```

**Cost:** ~$0.50 to index ~500 files (one-time cost)

---

## ğŸ¯ CÃC LOáº I CÃ‚U Há»I BOT CÃ“ THá»‚ TRáº¢ Lá»œI:

### Architecture & Design:
- â“ "Giáº£i thÃ­ch authentication flow trong há»‡ thá»‘ng"
- â“ "LÃ m sao session vÃ  JWT Ä‘Æ°á»£c sá»­ dá»¥ng?"
- â“ "MÃ´ táº£ cáº¥u trÃºc cá»§a Grade Model"

### Code Navigation:
- â“ "StudentController á»Ÿ Ä‘Ã¢u vÃ  lÃ m gÃ¬?"
- â“ "TÃ¬m code validate Ä‘iá»ƒm sá»‘ tá»« 0-10"
- â“ "AuthorizeRole attribute Ä‘Æ°á»£c implement nhÆ° tháº¿ nÃ o?"

### Debugging:
- â“ "Táº¡i sao khÃ´ng xÃ³a Ä‘Æ°á»£c sinh viÃªn cÃ³ Ä‘iá»ƒm?"
- â“ "LÃ m sao fix lá»—i OPENJSON trong pagination?"
- â“ "Giáº£i thÃ­ch lá»—i 'Port 4200 already in use'"

### Best Practices:
- â“ "CÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ thÃªm validation cho model?"
- â“ "LÃ m sao implement role-based authorization?"
- â“ "Best practice cho EF Core relationships?"

### Feature Implementation:
- â“ "LÃ m sao Ä‘á»ƒ thÃªm má»™t API endpoint má»›i?"
- â“ "Steps Ä‘á»ƒ táº¡o CRUD module cho entity má»›i"
- â“ "CÃ¡ch export data sang Excel nhÆ° trong StudentsController?"

---

## ğŸ“Š SO SÃNH: Tawk.to KB vs RAG System

| Feature | Tawk.to KB | RAG System |
|---------|-----------|------------|
| **Setup Time** | 10 phÃºt | 30 phÃºt - 2 giá» |
| **Cost** | FREE | ~$10/thÃ¡ng |
| **CÃ¢u há»i support** | General Q&A | Code-specific |
| **Hiá»ƒu code** | âŒ | âœ… |
| **Show code snippets** | âŒ | âœ… |
| **Context aware** | âŒ | âœ… Full |
| **Update knowledge** | Manual | Auto (tá»« code) |
| **Use cases** | User support | Developer assistant |

**KHUYáº¾N NGHá»Š:**
- **Tawk.to**: Cho end users (Admin, Teacher, Student)
- **RAG**: Cho developers vÃ  technical questions

**BOTH**: Báº­t cáº£ 2! User há»i "LÃ m sao thÃªm sinh viÃªn?" â†’ Tawk.to tráº£ lá»i. Developer há»i "StudentController.Create method hoáº¡t Ä‘á»™ng tháº¿ nÃ o?" â†’ RAG tráº£ lá»i.

---

## ğŸ”§ TROUBLESHOOTING

### Lá»—i: "OpenAI API key not found"
- Check `appsettings.Development.json` cÃ³ API key chÆ°a
- Verify key cÃ²n valid: https://platform.openai.com/api-keys

### Lá»—i: "Rate limit exceeded"
- OpenAI cÃ³ limit: 3 requests/min (free tier)
- Upgrade to paid tier hoáº·c wait 1 phÃºt

### Lá»—i: "Pinecone connection failed"
- Check API key vÃ  environment name
- Verify index name Ä‘Ãºng
- Fallback: Bot váº«n work vá»›i sample docs

### Bot tráº£ lá»i khÃ´ng chÃ­nh xÃ¡c:
- Current: Bot dÃ¹ng sample docs â†’ khÃ´ng cÃ³ Ä‘á»§ context
- Solution: Index codebase vÃ o Pinecone (see above)

### CÃ¢u há»i khÃ´ng Ä‘Æ°á»£c tráº£ lá»i:
- Check Console (F12) xem cÃ³ lá»—i API khÃ´ng
- Verify backend Ä‘ang cháº¡y trÃªn port 5298
- Check proxy config trong angular.json

---

## ğŸ’¡ OPTIMIZATION TIPS

### 1. Reduce Cost:
```json
{
  "OpenAI": {
    "Model": "gpt-3.5-turbo" // Thay vÃ¬ gpt-4, ráº» hÆ¡n 10x
  }
}
```

### 2. Improve Speed:
- Cache frequent questions trong localStorage
- Implement streaming responses (SSE)
- Use smaller chunk sizes (500 tokens)

### 3. Better Accuracy:
- Index more context (comments, README, docs)
- Increase `topK` tá»« 5 â†’ 10 documents
- Add example Q&A pairs vÃ o system prompt

### 4. Production Ready:
- Add rate limiting
- Implement user feedback (ğŸ‘/ğŸ‘)
- Track popular questions
- Add conversation memory

---

## ğŸ“ˆ USAGE METRICS

Track trong backend:
```csharp
// Log every question
_logger.LogInformation("RAG Question: {question} from {user}", question, userId);

// Track response time
var stopwatch = Stopwatch.StartNew();
var response = await _ragService.AskQuestion(question);
stopwatch.Stop();
_logger.LogInformation("Response time: {ms}ms", stopwatch.ElapsedMilliseconds);
```

---

## ğŸ“ LEARNING RESOURCES

**RAG Concepts:**
- https://www.pinecone.io/learn/retrieval-augmented-generation/
- https://platform.openai.com/docs/guides/embeddings

**OpenAI API:**
- https://platform.openai.com/docs/api-reference
- https://cookbook.openai.com/

**Vector Databases:**
- Pinecone: https://docs.pinecone.io/
- ChromaDB: https://www.trychroma.com/

---

## âœ… CHECKLIST

- [ ] Get OpenAI API key
- [ ] Update `appsettings.Development.json`
- [ ] Build backend (dotnet build)
- [ ] Test `/api/chat/health` endpoint
- [ ] Test `/api/chat/ask` with sample question
- [ ] Run Angular (npm start)
- [ ] Open http://localhost:4200
- [ ] Click "ğŸ¤– AI Assistant" button
- [ ] Ask technical question about code
- [ ] Verify response with code snippets
- [ ] (Optional) Setup Pinecone
- [ ] (Optional) Run index_codebase.py
- [ ] (Optional) Test with full codebase context

---

## ğŸš€ NEXT STEPS

1. **Test vá»›i OpenAI** (30 phÃºt):
   - Get API key
   - Update config
   - Run vÃ  test

2. **Setup Vector DB** (1-2 giá») náº¿u muá»‘n bot thÃ´ng minh hÆ¡n:
   - Sign up Pinecone
   - Run indexing script
   - Test vá»›i real codebase search

3. **Customize** (optional):
   - Thay Ä‘á»•i system prompt trong RagService.cs
   - Add thÃªm sample questions
   - Customize UI colors

4. **Production** (náº¿u deploy):
   - Move API keys to Azure Key Vault
   - Add rate limiting
   - Implement caching
   - Monitor costs

---

**ğŸ‰ RAG System sáºµn sÃ ng! Bot giá» cÃ³ thá»ƒ Ä‘á»c vÃ  hiá»ƒu CODE thá»±c sá»±!**
